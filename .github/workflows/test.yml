name: Test

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ '**' ]
  workflow_dispatch:

permissions:
  checks: write
  contents: read
  pull-requests: write

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6
      - name: Build the Docker image
        run: docker build . -t ${{ github.repository }}:$(date +%s)

  test:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        database: [postgres, sqlite]
    steps:
      - uses: actions/checkout@v6
      # PostgreSQL tests: Docker-based with Testcontainers
      - name: Build the testing image
        if: matrix.database == 'postgres'
        run: docker build . --file Dockerfile --target test --tag test
      - name: Run the test container
        if: matrix.database == 'postgres'
        run: docker run --name test -v /var/run/docker.sock:/var/run/docker.sock test
      - name: Copy the tests from the container
        if: matrix.database == 'postgres' && always()
        run: |
          if docker ps -a --format '{{.Names}}' | grep -qx test; then
            docker cp test:/tests tests
          else
            echo "Test container 'test' not found; skipping tests copy."
          fi
      - name: Copy the reports from the container
        if: matrix.database == 'postgres' && always()
        run: |
          if docker ps -a --format '{{.Names}}' | grep -qx test; then
            docker cp test:/reports reports
          else
            echo "Test container 'test' not found; skipping reports copy."
          fi
      # SQLite tests: Maven-based with in-memory SQLite
      - name: Set up Java
        if: matrix.database == 'sqlite'
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '25'
      - name: Install Bun
        if: matrix.database == 'sqlite'
        uses: oven-sh/setup-bun@v2
      - name: Install Python
        if: matrix.database == 'sqlite'
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'
      - name: Run SQLite tests
        if: matrix.database == 'sqlite'
        run: ./mvnw test surefire-report:report -Dspring.profiles.active=test,sqlite,scripts
      - name: Collect SQLite test results
        if: matrix.database == 'sqlite' && always()
        run: |
          mkdir -p tests reports
          cp target/surefire-reports/*.xml tests/ 2>/dev/null || true
          cp -r target/reports/* reports/ 2>/dev/null || true
          cp target/reports/surefire.html reports/index.html 2>/dev/null || true
      # Common reporting steps
      - name: Publish Unit Test Results
        uses: dorny/test-reporter@v2.5.0
        if: always()
        continue-on-error: true
        with:
          name: Test Results (${{ matrix.database }})
          path: "tests/*.xml"
          reporter: java-junit
      - name: Generate Test Summary
        if: always()
        id: test_summary
        run: |
          # Count total tests, failures, errors, and skipped
          if [ -d "tests" ] && ls tests/*.xml 1>/dev/null 2>&1; then
            TOTAL=$(grep -r "testsuite" tests/*.xml | grep -oP 'tests="\K[0-9]+' | awk '{s+=$1} END {print s}')
            FAILURES=$(grep -r "testsuite" tests/*.xml | grep -oP 'failures="\K[0-9]+' | awk '{s+=$1} END {print s}')
            ERRORS=$(grep -r "testsuite" tests/*.xml | grep -oP 'errors="\K[0-9]+' | awk '{s+=$1} END {print s}')
            SKIPPED=$(grep -r "testsuite" tests/*.xml | grep -oP 'skipped="\K[0-9]+' | awk '{s+=$1} END {print s}')
            
            # Default to 0 if empty
            TOTAL=${TOTAL:-0}
            FAILURES=${FAILURES:-0}
            ERRORS=${ERRORS:-0}
            SKIPPED=${SKIPPED:-0}
            
            # Calculate passed tests
            PASSED=$((TOTAL - FAILURES - ERRORS - SKIPPED))
            
            echo "total=$TOTAL" >> $GITHUB_OUTPUT
            echo "passed=$PASSED" >> $GITHUB_OUTPUT
            echo "failures=$FAILURES" >> $GITHUB_OUTPUT
            echo "errors=$ERRORS" >> $GITHUB_OUTPUT
            echo "skipped=$SKIPPED" >> $GITHUB_OUTPUT
            
            # Determine if tests failed
            if [ $((FAILURES + ERRORS)) -gt 0 ]; then
              echo "has_failures=true" >> $GITHUB_OUTPUT
            else
              echo "has_failures=false" >> $GITHUB_OUTPUT
            fi
            
            # Create workflow summary
            echo "## Test Results Summary (${{ matrix.database }})" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Metric | Count |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| Total Tests | $TOTAL |" >> $GITHUB_STEP_SUMMARY
            echo "| âœ… Passed | $PASSED |" >> $GITHUB_STEP_SUMMARY
            echo "| âŒ Failures | $FAILURES |" >> $GITHUB_STEP_SUMMARY
            echo "| ðŸ’¥ Errors | $ERRORS |" >> $GITHUB_STEP_SUMMARY
            echo "| â­ï¸ Skipped | $SKIPPED |" >> $GITHUB_STEP_SUMMARY
          else
            echo "No test results found"
            echo "has_failures=false" >> $GITHUB_OUTPUT
            echo "âš ï¸ No test results found" >> $GITHUB_STEP_SUMMARY
          fi
      - name: Generate Coverage Summary
        if: always()
        id: coverage_summary
        run: |
          COVERAGE_CSV="reports/coverage/jacoco.csv"
          if [ -f "$COVERAGE_CSV" ]; then
            # Validate CSV header matches expected JaCoCo format
            HEADER=$(head -1 "$COVERAGE_CSV")
            EXPECTED_HEADER="GROUP,PACKAGE,CLASS,INSTRUCTION_MISSED,INSTRUCTION_COVERED,BRANCH_MISSED,BRANCH_COVERED,LINE_MISSED,LINE_COVERED,COMPLEXITY_MISSED,COMPLEXITY_COVERED,METHOD_MISSED,METHOD_COVERED"
            if [ "$HEADER" != "$EXPECTED_HEADER" ]; then
              echo "::warning::JaCoCo CSV header format has changed. Coverage parsing may be inaccurate."
            fi

            # Sum up all coverage counters from CSV (skip header line)
            INST_MISSED=$(tail -n +2 "$COVERAGE_CSV" | awk -F',' '{s+=$4} END {print s+0}')
            INST_COVERED=$(tail -n +2 "$COVERAGE_CSV" | awk -F',' '{s+=$5} END {print s+0}')
            BRANCH_MISSED=$(tail -n +2 "$COVERAGE_CSV" | awk -F',' '{s+=$6} END {print s+0}')
            BRANCH_COVERED=$(tail -n +2 "$COVERAGE_CSV" | awk -F',' '{s+=$7} END {print s+0}')
            LINE_MISSED=$(tail -n +2 "$COVERAGE_CSV" | awk -F',' '{s+=$8} END {print s+0}')
            LINE_COVERED=$(tail -n +2 "$COVERAGE_CSV" | awk -F',' '{s+=$9} END {print s+0}')
            METHOD_MISSED=$(tail -n +2 "$COVERAGE_CSV" | awk -F',' '{s+=$12} END {print s+0}')
            METHOD_COVERED=$(tail -n +2 "$COVERAGE_CSV" | awk -F',' '{s+=$13} END {print s+0}')

            # Calculate percentages
            INST_TOTAL=$((INST_MISSED + INST_COVERED))
            BRANCH_TOTAL=$((BRANCH_MISSED + BRANCH_COVERED))
            LINE_TOTAL=$((LINE_MISSED + LINE_COVERED))
            METHOD_TOTAL=$((METHOD_MISSED + METHOD_COVERED))

            if [ "$INST_TOTAL" -gt 0 ]; then
              INST_PCT=$(awk "BEGIN {printf \"%.1f\", ($INST_COVERED / $INST_TOTAL) * 100}")
            else
              INST_PCT="0.0"
            fi
            if [ "$BRANCH_TOTAL" -gt 0 ]; then
              BRANCH_PCT=$(awk "BEGIN {printf \"%.1f\", ($BRANCH_COVERED / $BRANCH_TOTAL) * 100}")
            else
              BRANCH_PCT="0.0"
            fi
            if [ "$LINE_TOTAL" -gt 0 ]; then
              LINE_PCT=$(awk "BEGIN {printf \"%.1f\", ($LINE_COVERED / $LINE_TOTAL) * 100}")
            else
              LINE_PCT="0.0"
            fi
            if [ "$METHOD_TOTAL" -gt 0 ]; then
              METHOD_PCT=$(awk "BEGIN {printf \"%.1f\", ($METHOD_COVERED / $METHOD_TOTAL) * 100}")
            else
              METHOD_PCT="0.0"
            fi

            echo "has_coverage=true" >> $GITHUB_OUTPUT
            echo "instruction_pct=$INST_PCT" >> $GITHUB_OUTPUT
            echo "branch_pct=$BRANCH_PCT" >> $GITHUB_OUTPUT
            echo "line_pct=$LINE_PCT" >> $GITHUB_OUTPUT
            echo "line_covered=$LINE_COVERED" >> $GITHUB_OUTPUT
            echo "line_total=$LINE_TOTAL" >> $GITHUB_OUTPUT
            echo "method_pct=$METHOD_PCT" >> $GITHUB_OUTPUT

            # Add to workflow summary
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "## Code Coverage" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Metric | Coverage |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|----------|" >> $GITHUB_STEP_SUMMARY
            echo "| Instructions | $INST_PCT% |" >> $GITHUB_STEP_SUMMARY
            echo "| Branches | $BRANCH_PCT% |" >> $GITHUB_STEP_SUMMARY
            echo "| Lines | $LINE_PCT% ($LINE_COVERED / $LINE_TOTAL) |" >> $GITHUB_STEP_SUMMARY
            echo "| Methods | $METHOD_PCT% |" >> $GITHUB_STEP_SUMMARY
          else
            echo "has_coverage=false" >> $GITHUB_OUTPUT
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "âš ï¸ No coverage report found" >> $GITHUB_STEP_SUMMARY
          fi
      - name: Comment on PR with Test Results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v8
        with:
          # language=JavaScript
          script: |
            const fs = require('fs');
            const path = require('path');
            
            const total = '${{ steps.test_summary.outputs.total }}' || '0';
            const passed = '${{ steps.test_summary.outputs.passed }}' || '0';
            const failures = '${{ steps.test_summary.outputs.failures }}' || '0';
            const errors = '${{ steps.test_summary.outputs.errors }}' || '0';
            const skipped = '${{ steps.test_summary.outputs.skipped }}' || '0';
            const hasFailures = '${{ steps.test_summary.outputs.has_failures }}' === 'true';
            
            const hasCoverage = '${{ steps.coverage_summary.outputs.has_coverage }}' === 'true';
            const instructionPct = '${{ steps.coverage_summary.outputs.instruction_pct }}' || '0';
            const branchPct = '${{ steps.coverage_summary.outputs.branch_pct }}' || '0';
            const linePct = '${{ steps.coverage_summary.outputs.line_pct }}' || '0';
            const lineCovered = '${{ steps.coverage_summary.outputs.line_covered }}' || '0';
            const lineTotal = '${{ steps.coverage_summary.outputs.line_total }}' || '0';
            const methodPct = '${{ steps.coverage_summary.outputs.method_pct }}' || '0';
            
            let emoji = 'âœ…';
            let status = 'All tests passed!';
            
            if (hasFailures) {
              emoji = 'âŒ';
              status = 'Some tests failed!';
            }
            
            let comment = `## ${emoji} Test Results (${{ matrix.database }})\n\n`;
            comment += `**${status}**\n\n`;
            comment += `| Metric | Count |\n`;
            comment += `|--------|-------|\n`;
            comment += `| Total Tests | ${total} |\n`;
            comment += `| âœ… Passed | ${passed} |\n`;
            comment += `| âŒ Failures | ${failures} |\n`;
            comment += `| ðŸ’¥ Errors | ${errors} |\n`;
            comment += `| â­ï¸ Skipped | ${skipped} |\n\n`;
            
            // Add coverage section
            if (hasCoverage) {
              comment += `### ðŸ“Š Code Coverage\n\n`;
              comment += `| Metric | Coverage |\n`;
              comment += `|--------|----------|\n`;
              comment += `| Instructions | ${instructionPct}% |\n`;
              comment += `| Branches | ${branchPct}% |\n`;
              comment += `| Lines | ${linePct}% (${lineCovered} / ${lineTotal}) |\n`;
              comment += `| Methods | ${methodPct}% |\n\n`;
            }
            
            // Add link to detailed report
            const url = `https://${context.repo.owner}.github.io/${context.repo.repo}/reports/junit-reports-pr-${context.issue.number}/`;
            comment += `ðŸ“‹ [View detailed test report](${url})\n`;
            if (hasCoverage) {
              comment += `ðŸ“Š [View detailed coverage report](${url}coverage/)\n`;
            }
            comment += `\n`;
            
            // If there are failures, try to extract failure details
            if (hasFailures) {
              comment += `### ðŸ” Test Failures\n\n`;
              
              try {
                const testsDir = 'tests';
                if (fs.existsSync(testsDir)) {
                  const files = fs.readdirSync(testsDir).filter(f => f.endsWith('.xml'));
                  const failureDetails = [];
                  
                  for (const file of files) {
                    const content = fs.readFileSync(path.join(testsDir, file), 'utf8');
                    
                    // Parse XML for failures and errors
                    const testcaseRegex = /<testcase[^>]*name="([^"]*)"[^>]*classname="([^"]*)"[^>]*time="([^"]*)"[^>]*>([\s\S]*?)<\/testcase>/g;
                    let match;
                    
                    while ((match = testcaseRegex.exec(content)) !== null) {
                      const [, testName, className, time, body] = match;
                      
                      // Check if this testcase has a failure or error
                      if (body.includes('<failure') || body.includes('<error')) {
                        const failureMatch = body.match(/<(?:failure|error)[^>]*message="([^"]*)"[^>]*>([\s\S]*?)<\/(?:failure|error)>/);
                        if (failureMatch) {
                          const [, message, details] = failureMatch;
                          failureDetails.push({
                            className: className,
                            testName: testName,
                            message: message,
                            details: details.trim()
                          });
                        }
                      }
                    }
                  }
                  
                  if (failureDetails.length > 0) {
                    // Limit to first 10 failures to avoid huge comments
                    const displayFailures = failureDetails.slice(0, 10);
                    
                    for (const failure of displayFailures) {
                      comment += `#### \`${failure.className}.${failure.testName}\`\n\n`;
                      comment += `**Message:** ${failure.message}\n\n`;
                      
                      // Truncate long stack traces
                      if (failure.details.length > 500) {
                        comment += `<details>\n<summary>Stack trace (click to expand)</summary>\n\n\`\`\`\n${failure.details.substring(0, 1000)}...\n\`\`\`\n</details>\n\n`;
                      } else if (failure.details.length > 0) {
                        comment += `\`\`\`\n${failure.details}\n\`\`\`\n\n`;
                      }
                    }
                    
                    if (failureDetails.length > 10) {
                      comment += `\n*... and ${failureDetails.length - 10} more failures. See the detailed report for all failures.*\n`;
                    }
                  }
                }
              } catch (error) {
                console.error('Error parsing test results:', error);
                comment += `\n*Could not parse detailed test failures. Please check the full report.*\n`;
              }
            }
            
            // Add marker to identify our comment
            comment += `\n<!-- test-results-comment-${{ matrix.database }} -->`;
            
            // Find existing comment and update it, or create new one
            const comments = await github.paginate(
              github.rest.issues.listComments,
              {
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
              }
            );
            
            const botComment = comments.find(comment => 
              comment.body.includes('<!-- test-results-comment-${{ matrix.database }} -->')
            );
            
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment
              });
            } else {
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            }
      - name: Upload PR Report
        if: github.event_name == 'pull_request' && always()
        uses: actions/upload-artifact@v6
        with:
          name: junit-reports-${{ matrix.database }}-pr-${{ github.event.pull_request.number }}
          path: reports
          retention-days: 7
      - name: Upload Reports
        if: github.event_name != 'pull_request' && always()
        uses: actions/upload-artifact@v6
        with:
          name: junit-reports-${{ matrix.database }}-${{ github.ref_name }}-${{ github.run_number }}
          path: reports
          retention-days: 90

  clean:
    needs: test
    if: always()
    runs-on: ubuntu-latest
    permissions:
      actions: write
    steps:
      - name: Cleanup old branch artifacts
        if: github.event_name != 'pull_request'
        uses: actions/github-script@v8
        with:
          # language=JavaScript
          script: |
            const maxVersions = 5;
            const response = await github.rest.actions.listArtifactsForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              per_page: 100
            });
            const artifacts = response.data.artifacts
              .filter(artifact => artifact.name.startsWith('junit-reports-') && artifact.name.includes('${{ github.ref_name }}'));
            if (artifacts.length > maxVersions) {
              // Sort by created_at descending
              artifacts.sort((a, b) => new Date(b.created_at) - new Date(a.created_at));
              // Delete all but the latest maxVersions
              for (const artifact of artifacts.slice(maxVersions)) {
                console.log('Deleting artifact:', artifact.name);
                await github.rest.actions.deleteArtifact({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  artifact_id: artifact.id
                });
              }
            }
      - name: Cleanup old PR artifacts
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v8
        with:
          # language=JavaScript
          script: |
            const maxVersions = 1;
            const response = await github.rest.actions.listArtifactsForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              per_page: 100
            });
            const artifacts = response.data.artifacts
              .filter(artifact => artifact.name === 'junit-reports-pr-${{ github.event.pull_request.number }}');
            if (artifacts.length > maxVersions) {
              // Sort by created_at descending
              artifacts.sort((a, b) => new Date(b.created_at) - new Date(a.created_at));
              // Delete all but the latest maxVersions
              for (const artifact of artifacts.slice(maxVersions)) {
                console.log('Deleting artifact:', artifact.name);
                await github.rest.actions.deleteArtifact({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  artifact_id: artifact.id
                });
              }
            }
